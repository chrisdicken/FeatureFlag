{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Feature Flags to Test Faster Data Processing Techniques\n",
    "\n",
    "I have two functions which search for the longest strings in a large datasets.\n",
    "I will use feature flags to switch between them, testing which is more efficient. \n",
    "\n",
    "Function 1, Simple:\n",
    "1. Measures length of each string\n",
    "2. Returns string with longest length\n",
    "\n",
    "Function 2, MapReduce:\n",
    "1. You split your dataset up into small chunks\n",
    "2. Find longest string in each chunk separately\n",
    "3. Group chunks back together and process the smaller and simpler reduced output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Flag Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature flag client\n",
    "import ldclient\n",
    "from ldclient.config import Config\n",
    "\n",
    "#test project SDK key\n",
    "ldclient.set_config(Config(\"sdk-a3b73679-1452-4129-9909-ec5759094fa2\"))\n",
    "ld_client = ldclient.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simple Function\n",
    "def longest_strings(string):\n",
    "    longest_string = None\n",
    "    Longest_length = 0\n",
    "    for s in string:\n",
    "        if len(s) > Longest_length:\n",
    "            longest_string = s\n",
    "            Longest_length = len(s)\n",
    "    return longest_string\n",
    "\n",
    "##### map reduce functions\n",
    "\n",
    "def reducer(p, c):\n",
    "    if p[1] > c[1]:\n",
    "        return p\n",
    "    return c\n",
    "\n",
    "def mapper(chunk):\n",
    "    list_of_lengths = map(len, chunk)\n",
    "    mapped = zip(chunk, list_of_lengths)\n",
    "    return reduce(reducer, mapped)\n",
    "\n",
    "#split list into N number of other lists\n",
    "def chunker_list(seq, size):\n",
    "    return (seq[i::size] for i in range(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_example = [\"Python\", \"apple\", \"Alex long\"]*1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Flag OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapReduce Feature Off:  Alex long\n",
      "0.28125\n"
     ]
    }
   ],
   "source": [
    "show_feature = ld_client.variation(\"MapReduce\", {\"key\": \"chris@test.com\"}, False)\n",
    "\n",
    "if show_feature:\n",
    "    t2 = time.process_time()\n",
    "    data_chunks = chunker_list(string_example, 2)\n",
    "\n",
    "    #step 1\n",
    "    from Mapper import mapper\n",
    "    mapped = map(mapper, data_chunks)\n",
    "\n",
    "    #step 2\n",
    "    reduced = reduce(reducer, mapped)\n",
    "    print(\"MapReduce Feature On:   \"+str(reduced))\n",
    "    t3 = time.process_time()\n",
    "    print(t3-t2)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    t0 = time.process_time()\n",
    "    print(\"MapReduce Feature Off:  \"+longest_strings(string_example))\n",
    "    t1 = time.process_time()\n",
    "    print(t1-t0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Flag ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapReduce Feature On:   ('Alex long', 9)\n",
      "0.640625\n"
     ]
    }
   ],
   "source": [
    "show_feature = ld_client.variation(\"MapReduce\", {\"key\": \"chris@test.com\"}, False)\n",
    "\n",
    "if show_feature:\n",
    "    t2 = time.process_time()\n",
    "    data_chunks = chunker_list(string_example, 2)\n",
    "\n",
    "    #step 1\n",
    "    from Mapper import mapper\n",
    "    mapped = map(mapper, data_chunks)\n",
    "\n",
    "    #step 2\n",
    "    reduced = reduce(reducer, mapped)\n",
    "    print(\"MapReduce Feature On:   \"+str(reduced))\n",
    "    t3 = time.process_time()\n",
    "    print(t3-t2)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    t0 = time.process_time()\n",
    "    print(\"MapReduce Feature Off:  \"+longest_strings(string_example))\n",
    "    t1 = time.process_time()\n",
    "    print(t1-t0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. Our Feature Flag works\n",
    "2. MapReduce is slower, this is because usually we process the chunks in parallel with each logical CPU - for simplicity i did not do this for the demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
